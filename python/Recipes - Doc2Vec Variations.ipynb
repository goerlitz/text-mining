{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec trained on recipe instructions\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "* Create word embeddings for recipes.\n",
    "* Use word vectors for (traditional) segmentation, classification, and retrieval of recipes.\n",
    "\n",
    "Based on https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re                                                    # Regular Expressions\n",
    "import os.path                                               # File Operations\n",
    "import pandas as pd                                          # DataFrames & Manipulation\n",
    "from gensim.models.doc2vec import LabeledSentence, Doc2Vec   # Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input = \"../data/recipes.tsv.bz2\"\n",
    "\n",
    "# preserve empty strings (http://pandas-docs.github.io/pandas-docs-travis/io.html#na-values)\n",
    "train = pd.read_csv(train_input, delimiter=\"\\t\", quoting=3, encoding=\"utf-8\", keep_default_na=False)\n",
    "\n",
    "print \"loaded %d documents.\" % len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    norm_text = text.lower()\n",
    "    \n",
    "    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n",
    "        norm_text = norm_text.replace(char, ' ' + char + ' ')\n",
    "    \n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = [LabeledSentence(normalize(text).split(), [i]) for i, text in enumerate(train['instructions'])]\n",
    "\n",
    "print \"%d sentences in corpus\" % len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec Model\n",
    "\n",
    "see http://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "    class gensim.models.doc2vec.Doc2Vec(\n",
    "        documents=None,          # list of TaggedDocument elements\n",
    "        dm=1,                    # training algorithm. dm=1: 'distributed memory' (PV-DM).\n",
    "                                                       otherwise, 'distributed bag of words' (PV-DBOW).\n",
    "        dbow_words=0,            # 0 (default), if 1, trains word-vectors simultaneous with DBOW doc-vector\n",
    "        dm_mean=None,            # 0 (default), if 1, use the mean of context word vectors instead of sum.\n",
    "        dm_concat=0,             # 0 (default), if 1, use concatenation of (all) context vectors (slow).\n",
    "        dm_tag_count=1,          # 1 (default), expected document tags per document, when using dm_concat mode\n",
    "        docvecs=None,\n",
    "        docvecs_mapfile=None,\n",
    "        comment=None,\n",
    "        trim_rule=None,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_memory    =   1   # distributed memory model\n",
    "vector_mean    =   1   # compute mean of input word vectors\n",
    "num_features   = 300   # word vector dimensionality\n",
    "min_word_count =   2   # minimum word count\n",
    "num_workers    =   4   # number of threads to run in parallel\n",
    "context        =  10   # context window size\n",
    "downsampling   = 1e-3  # downsample setting for frequent words\n",
    "\n",
    "model_name = \"model-d2v_dm_%dfeatures_%dminwords_%dcontext\" % (num_features, min_word_count, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model or create new one\n",
    "if os.path.isfile(model_name):\n",
    "    model = Doc2Vec.load(model_name)\n",
    "    do_train = False\n",
    "else:\n",
    "    model = Doc2Vec(dm=1, dm_mean=1, size=num_features, min_count=min_word_count, window=context,\n",
    "                    sample=downsampling, workers=num_workers)\n",
    "    model.build_vocab(sentences)\n",
    "    do_train = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "train multiple epochs with decreasing learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from random import shuffle\n",
    "from datetime import datetime\n",
    "\n",
    "# configure usedful logging messages\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, sentences, passes=10, alpha=0.025, min_alpha=0.001):\n",
    "    alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "    print(\"START %s\" % datetime.now())\n",
    "\n",
    "    for epoch in range(passes):\n",
    "        shuffle(sentences)  # shuffling gets best results\n",
    "\n",
    "        model.alpha, model.min_alpha = alpha, alpha\n",
    "        model.train(sentences)\n",
    "\n",
    "        print(\"finished epoch %d (alpha: %f) - %s\" % (epoch + 1, alpha, datetime.now()))\n",
    "\n",
    "        alpha -= alpha_delta\n",
    "\n",
    "    print(\"END %s\" % str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    train_model(model, sentences, passes=30)\n",
    "\n",
    "    # finalize model to save memory\n",
    "    #model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "    # save model\n",
    "    model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model results\n",
    "\n",
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar([\"pasta\"], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.docvecs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recipe_no = 42\n",
    "ids = model.docvecs.most_similar(recipe_no, topn=20)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.loc[[recipe_no]+[id for id, score in ids]][['title','instructions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute vector for existing document\n",
    "\n",
    "Infer vector and use it as positive example (see also #https://groups.google.com/forum/#!msg/gensim/IH_u8HYVbpg/w9TX4yh2DgAJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = train['instructions'][recipe_no]\n",
    "wordvec = model.infer_vector(normalize(doc).split())\n",
    "ids = model.docvecs.most_similar(positive=[wordvec], topn=20)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.loc[[id for id, score in ids]][['title','instructions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute vector for new document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = u\"Wodka, Cointreau, Limettensaft, Cranberrysaft und Eis.\"\n",
    "wordvec = model.infer_vector(normalize(doc).split())\n",
    "ids = model.docvecs.most_similar(positive=[wordvec], topn=20)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.loc[[id for id, score in ids]][['title','instructions']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
